{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ab4049-536f-43ea-904a-cda757e46abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatOpenAI model initialized.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "llm = ChatOpenAI()\n",
    "print(\"ChatOpenAI model initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3628ee46-408d-4a77-805b-40b7b0eb4bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith can help with testing in several ways:\\n\\n1. Automated Testing: Langsmith can generate test cases automatically, reducing the time and effort required for manual testing. It can create a large number of test cases by varying input parameters and generate test data based on predefined rules.\\n\\n2. Test Coverage: Langsmith can analyze the code and identify areas that are not covered by existing tests. It can suggest additional test cases to improve code coverage and identify potential gaps in the testing strategy.\\n\\n3. Regression Testing: Langsmith can automatically generate test cases to ensure that code changes or updates do not introduce new bugs or regressions. It can compare the output of the modified code with the expected output to detect any discrepancies.\\n\\n4. Performance Testing: Langsmith can simulate different scenarios and generate test cases to evaluate the performance of the software under various conditions. It can measure response times, identify bottlenecks, and suggest optimizations to improve performance.\\n\\n5. Security Testing: Langsmith can generate test cases to identify potential security vulnerabilities in the software. It can simulate various attack scenarios, such as SQL injection or cross-site scripting, and provide insights into potential security weaknesses.\\n\\n6. Usability Testing: Langsmith can assist in generating test cases to evaluate the usability of the software. It can simulate user interactions and provide feedback on the user interface, accessibility, and overall user experience.\\n\\nOverall, Langsmith's capabilities in generating test cases, analyzing code, and simulating various scenarios can significantly enhance the testing process and help ensure the quality and reliability of the software.\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke simple request about langsmith\n",
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1734abc6-78be-4f3e-879f-1ef44bdceb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a powerful testing tool that can greatly assist in ensuring the quality and reliability of software applications. Here are some ways in which Langsmith can help with testing:\\n\\n1. Test Automation: Langsmith allows you to automate the execution of tests, saving time and effort compared to manual testing. It provides a user-friendly interface for creating, managing, and executing automated test scripts.\\n\\n2. Test Case Management: With Langsmith, you can easily create and organize test cases, test suites, and test plans. It provides a centralized repository for storing and managing all testing artifacts, making it easier to track progress and ensure test coverage.\\n\\n3. Test Data Management: Langsmith offers capabilities for managing test data, including creating and maintaining test data sets. This helps in ensuring that tests are executed with a variety of data scenarios, covering different use cases.\\n\\n4. Test Execution and Reporting: Langsmith allows you to execute tests across different platforms and environments, providing comprehensive test execution reports. These reports provide detailed insights into test results, including pass/fail status, logs, screenshots, and performance metrics.\\n\\n5. Integration with CI/CD: Langsmith seamlessly integrates with Continuous Integration and Continuous Deployment (CI/CD) pipelines, enabling you to easily incorporate testing into your software development workflow. This ensures that testing becomes an integral part of the development process, leading to more reliable and stable software releases.\\n\\nIn summary, Langsmith offers a wide range of testing capabilities, including test automation, test case management, test data management, and test execution reporting. By utilizing Langsmith, you can enhance the efficiency and effectiveness of your testing efforts, leading to higher quality software. Good Day Mate!')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer. End the response with 'Good Day Mate!'\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "# Combine these into a simple LLM chain\n",
    "chain = prompt | llm \n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e0b4d8e-d6ce-4a47-acbf-d4f5554ad80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, I am an AI assistant. You can call me Jenny. How can I assist you today?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt2 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Your name is Jenny.\"),\n",
    "    (\"human\", \"Hello, how are you?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "# Combine these into a simple LLM chain\n",
    "chain2 = prompt2 | llm \n",
    "chain2.invoke({\"input\": \"Hello, who are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c03848ec-75a4-476e-8602-e8a8b6f13be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can greatly assist with testing by providing a range of useful features and tools. Firstly, it offers automated testing capabilities which can help streamline the testing process and improve efficiency. With Langsmith, you can easily write test scripts using its user-friendly scripting language, making it simple to create and execute tests.\\n\\nAdditionally, Langsmith provides comprehensive reporting functionality, allowing you to generate detailed test reports that highlight any issues or failures encountered during testing. These reports can be invaluable in identifying areas that require further attention or improvement.\\n\\nMoreover, Langsmith supports integration with popular testing frameworks and tools, enabling seamless integration into your existing testing environment. It also offers support for different platforms and devices, ensuring that your tests can be executed across various operating systems and hardware configurations.\\n\\nLastly, Langsmith offers excellent documentation and support resources, including tutorials, guides, and a dedicated community forum. This ensures that users can easily access information and assistance when needed, maximizing the effectiveness of testing efforts.\\n\\nGood Day Mate!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding str parser at the end of chain to parse output as string\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b5c260-2c48-4d16-99fb-44e94d010498",
   "metadata": {},
   "source": [
    "## Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3219a7-e55f-4946-9aab-4e1b68b1ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Use embedding model from OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Build the index into vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a32c289-e71d-418a-bb0e-10ba24910d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by allowing users to visualize test results.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the document chain with the prompt template\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "# Run a query with 1-liner page content\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3565ff-a3b8-48b1-b477-7809ade4a966",
   "metadata": {},
   "source": [
    "### Using the vector store created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e91e3354-c976-4281-9af9-71814fc6df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by providing the ability to run a chain over data points and visualize the outputs. This allows for manual inspection of the results and evaluation of the model's performance. LangSmith also provides evaluators that can be used to automatically evaluate the results of test runs. Additionally, LangSmith makes it easy to assign feedback to runs and mark them as correct or incorrect, providing aggregate statistics for each test project.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f0449-f5d3-4989-b224-45218e040e96",
   "metadata": {},
   "source": [
    "## Conversation Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "402aec3b-e49b-486a-b020-eb29fd2dbd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62258060-3187-4fb6-8206-2d3e40a174d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='Skip to main contentğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by defaultâ€‹At LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript environments through process.env1.The benefit here is that all calls to LLMs, chains, agents, tools, and retrievers are logged to LangSmith. Around 90% of the time we donâ€™t even look at the traces, but the 10% of the time that we doâ€¦ itâ€™s so helpful. We can use LangSmith to debug:An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebuggingâ€‹Debugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?â€‹LLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string â†’ string (or chat messages â†’ chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content=\"You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoringâ€‹After all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.Weâ€™ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing â€” mirroring the debug mode approach.Weâ€™ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We're eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasetsâ€‹LangSmith makes it easy to curate datasets. However, these arenâ€™t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.â†©PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       " Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as \"feedback\" to the source runs, so you can easily filter and analyze them later.', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f19cb4-3c08-4a9d-b0e8-cc8fd07ce2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template that take chat_history\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "## New retrieval chain that\n",
    "## 1. Retrieve context / content\n",
    "## 2. Load LLM (OpenAI Chat)\n",
    "## 3. Prompt template with chat history\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d5ae553-275e-4832-a764-73e7a7381c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content='LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       "  Document(page_content='Skip to main contentğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by defaultâ€‹At LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript environments through process.env1.The benefit here is that all calls to LLMs, chains, agents, tools, and retrievers are logged to LangSmith. Around 90% of the time we donâ€™t even look at the traces, but the 10% of the time that we doâ€¦ itâ€™s so helpful. We can use LangSmith to debug:An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebuggingâ€‹Debugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?â€‹LLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string â†’ string (or chat messages â†’ chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       "  Document(page_content=\"You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoringâ€‹After all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.Weâ€™ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing â€” mirroring the debug mode approach.Weâ€™ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We're eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasetsâ€‹LangSmith makes it easy to curate datasets. However, these arenâ€™t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime environments without access to the environment, check out the FAQs.â†©PreviousLangSmithNextTracingOn by defaultDebuggingWhat was the exact input to the LLM?If I edit the prompt, how does that\", metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like creativity or humorTo sample and validate a subset of runs that were auto-evaluated, ensuring the automatic metrics are still reliable and capturing the right informationAll the annotations made using the queue are assigned as \"feedback\" to the source runs, so you can easily filter and analyze them later.', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en'})],\n",
       " 'answer': 'LangSmith can help test your LLM applications in several ways:\\n\\n1. Tracing: By enabling tracing in LangSmith, you can log all calls to LLMs, chains, agents, tools, and retrievers. This allows you to track and debug any unexpected behavior or issues that arise during testing.\\n\\n2. Debugging: LangSmith provides tools to debug LLMs, chains, and agents. It helps you identify the exact input to the LLM, which is often tricky and non-deterministic. This is particularly useful for understanding and troubleshooting the behavior of your application.\\n\\n3. Monitoring: Once your application is ready for production, LangSmith can be used for monitoring purposes. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. This helps ensure the reliability and performance of your LLM applications.\\n\\n4. Annotation Queues: LangSmith allows you to manually review and annotate runs through annotation queues. This is useful for assessing subjective qualities like creativity or humor, as well as validating the auto-evaluation results. The annotations can be used to analyze and improve your LLM applications.\\n\\n5. Exporting Datasets: LangSmith makes it easy to curate datasets, which can be exported for use in other contexts. This includes exporting datasets for use in OpenAI Evals or for fine-tuning purposes, such as with FireworksAI.\\n\\nOverall, LangSmith provides a range of features and tools to help you test, debug, monitor, and improve the reliability and performance of your LLM applications.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Run a test of LangChain with chat history\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5b87da-039b-4943-91c7-0f4b315b4f62",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f98174b-46cb-4aeb-b4a8-2bd17112453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a retriever tool to answer questions about LangSmith.\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3811139-8902-4625-bdda-e1693ed0bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Tavily Search tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search_tool = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "803b506d-7794-405e-a896-db5fcfcff434",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef6f47a-51dc-4820-bda6-1150f8a76f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe3a4aa7-831c-4b50-84dd-43cd90b2b393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangSmith can help with testing in several ways:\n",
      "\n",
      "1. Test Case Generation: LangSmith can generate test cases automatically based on the specifications of the software being tested. It uses advanced techniques such as symbolic execution and constraint solving to generate test inputs that cover different execution paths and edge cases.\n",
      "\n",
      "2. Test Oracles: LangSmith can help in defining test oracles, which are the expected outputs or behaviors of the software under test. It can analyze the specifications and requirements of the software to automatically generate assertions or checks that can be used as test oracles.\n",
      "\n",
      "3. Test Coverage Analysis: LangSmith can analyze the code coverage of the test cases to determine which parts of the software have been exercised during testing. This helps in identifying areas of the code that have not been tested and may require additional test cases.\n",
      "\n",
      "4. Test Prioritization: LangSmith can prioritize the execution of test cases based on their likelihood of finding bugs or their impact on the system. It uses techniques such as mutation analysis and fault localization to determine the effectiveness of each test case and prioritize them accordingly.\n",
      "\n",
      "5. Test Result Analysis: LangSmith can analyze the results of the test cases to identify patterns or trends that may indicate the presence of bugs or performance issues. It can also help in identifying the root causes of failures and provide suggestions for fixing them.\n",
      "\n",
      "Overall, LangSmith can assist in automating various aspects of the testing process, making it more efficient and effective.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing in several ways:\\n\\n1. Test Case Generation: LangSmith can generate test cases automatically based on the specifications of the software being tested. It uses advanced techniques such as symbolic execution and constraint solving to generate test inputs that cover different execution paths and edge cases.\\n\\n2. Test Oracles: LangSmith can help in defining test oracles, which are the expected outputs or behaviors of the software under test. It can analyze the specifications and requirements of the software to automatically generate assertions or checks that can be used as test oracles.\\n\\n3. Test Coverage Analysis: LangSmith can analyze the code coverage of the test cases to determine which parts of the software have been exercised during testing. This helps in identifying areas of the code that have not been tested and may require additional test cases.\\n\\n4. Test Prioritization: LangSmith can prioritize the execution of test cases based on their likelihood of finding bugs or their impact on the system. It uses techniques such as mutation analysis and fault localization to determine the effectiveness of each test case and prioritize them accordingly.\\n\\n5. Test Result Analysis: LangSmith can analyze the results of the test cases to identify patterns or trends that may indicate the presence of bugs or performance issues. It can also help in identifying the root causes of failures and provide suggestions for fixing them.\\n\\nOverall, LangSmith can assist in automating various aspects of the testing process, making it more efficient and effective.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test LangSmith related question\n",
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074be44e-59e2-44b4-977b-c23fc71c8be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://en.climate-data.org/north-america/united-states-of-america/california/san-francisco-385/t/january-1/', 'content': 'San Francisco Weather in January  San Francisco weather in January San Francisco weather by month // weather averages 9.6 (49.2) 6.2 (43.2) 14 (57.3) 113  you can find all information about the weather in San Francisco in January:  San Francisco weather in January // weather averages Airport close to San FranciscoData: 1991 - 2021 Min. Temperature °C (°F), Max. Temperature °C (°F), Precipitation / Rainfall mm (in), Humidity, Rainy days. Data: 1999 - 2019: avg. Sun hours San Francisco weather and climate for further months San Francisco in February San Francisco in March San Francisco in April San Francisco in May San Francisco in June San Francisco in July'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco can vary depending on the time of year. In January, the average minimum temperature is around 9.6°C (49.2°F) and the average maximum temperature is around 14°C (57.3°F). The city experiences an average of 113mm (4.4 inches) of precipitation during this month. If you would like more information about the weather in San Francisco for other months, please let me know.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in SF?',\n",
       " 'output': 'The weather in San Francisco can vary depending on the time of year. In January, the average minimum temperature is around 9.6°C (49.2°F) and the average maximum temperature is around 14°C (57.3°F). The city experiences an average of 113mm (4.4 inches) of precipitation during this month. If you would like more information about the weather in San Francisco for other months, please let me know.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test non-LangSmith related question, it should use Tavily search\n",
    "agent_executor.invoke({\"input\": \"what is the weather in SF?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5054331a-922c-4369-8145-41f37ebef948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangSmith can help test your LLM applications in the following ways:\n",
      "\n",
      "1. Personal Statement Review: LangSmith can provide feedback and suggestions on your personal statement to ensure it effectively communicates your motivations, experiences, and goals. This includes checking for clarity, coherence, grammar, and overall impact.\n",
      "\n",
      "2. Resume/CV Review: LangSmith can review your resume or CV to ensure it is well-structured, highlights your relevant experiences and achievements, and adheres to the standard format for LLM applications.\n",
      "\n",
      "3. Recommendation Letter Guidance: LangSmith can provide guidance on selecting appropriate recommenders, as well as tips on how to request strong recommendation letters. Additionally, LangSmith can review draft recommendation letters to ensure they effectively highlight your strengths and qualifications.\n",
      "\n",
      "4. Application Strategy: LangSmith can help you develop a comprehensive application strategy, including selecting the right law schools, understanding their specific requirements, and organizing your application materials.\n",
      "\n",
      "5. Interview Preparation: LangSmith can provide guidance and practice for LLM interviews, including common interview questions, tips for effective communication, and strategies for showcasing your qualifications.\n",
      "\n",
      "6. Scholarship and Financial Aid Assistance: LangSmith can provide information and guidance on available scholarships and financial aid options for LLM programs, helping you navigate the application process and increase your chances of securing funding.\n",
      "\n",
      "Please note that LangSmith is an AI-powered assistant and does not have direct access to your application materials or the ability to submit applications on your behalf. Its role is to provide guidance, suggestions, and information to help you improve your application.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'output': 'LangSmith can help test your LLM applications in the following ways:\\n\\n1. Personal Statement Review: LangSmith can provide feedback and suggestions on your personal statement to ensure it effectively communicates your motivations, experiences, and goals. This includes checking for clarity, coherence, grammar, and overall impact.\\n\\n2. Resume/CV Review: LangSmith can review your resume or CV to ensure it is well-structured, highlights your relevant experiences and achievements, and adheres to the standard format for LLM applications.\\n\\n3. Recommendation Letter Guidance: LangSmith can provide guidance on selecting appropriate recommenders, as well as tips on how to request strong recommendation letters. Additionally, LangSmith can review draft recommendation letters to ensure they effectively highlight your strengths and qualifications.\\n\\n4. Application Strategy: LangSmith can help you develop a comprehensive application strategy, including selecting the right law schools, understanding their specific requirements, and organizing your application materials.\\n\\n5. Interview Preparation: LangSmith can provide guidance and practice for LLM interviews, including common interview questions, tips for effective communication, and strategies for showcasing your qualifications.\\n\\n6. Scholarship and Financial Aid Assistance: LangSmith can provide information and guidance on available scholarships and financial aid options for LLM programs, helping you navigate the application process and increase your chances of securing funding.\\n\\nPlease note that LangSmith is an AI-powered assistant and does not have direct access to your application materials or the ability to submit applications on your behalf. Its role is to provide guidance, suggestions, and information to help you improve your application.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Can add chat history\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "agent_executor.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a65606-6090-4edc-91be-845705a40713",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afcd716a-21e6-4bcd-9e94-5182a9001977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccaa9ddb-2148-4803-bdfb-dab6823e0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b423f921-5503-48f7-a41d-5b898cddc2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wikipedia'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5673a4a5-fcf9-4cf2-83d0-00320fa8ce66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b2e4094-a619-4667-8cd8-d229e68107a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00e99b88-aadb-4d75-a8a3-68889f7f1e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.return_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c471a0ad-6ead-4a71-9855-231ce0f46198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.run({\"query\": \"langchain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47684d42-4a92-4d89-80d6-bdda22bb687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb4994-5108-4556-9d88-c37e96b3ea48",
   "metadata": {},
   "source": [
    "### Customizing Default Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7629356-df76-41a7-aa6c-6140eac676f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki-tool\n",
      "look up things in wikipedia\n",
      "{'query': {'title': 'Query', 'description': 'query to look up in Wikipedia, should be 3 or less words', 'type': 'string'}}\n",
      "True\n",
      "Page: LangChain\n",
      "Summary: LangChain is a framework designed to simplify the creation of applications \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class WikiInputs(BaseModel):\n",
    "    \"\"\"Inputs to the wikipedia tool.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        description=\"query to look up in Wikipedia, should be 3 or less words\"\n",
    "    )\n",
    "\n",
    "tool = WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")\n",
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.args)\n",
    "print(tool.return_direct)\n",
    "print(tool.run(\"langchain\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
